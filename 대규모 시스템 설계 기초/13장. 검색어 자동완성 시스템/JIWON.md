# 13장. 검색어 자동완성 시스템

---

가장 많이 이용된 검색어 k개를 자동완성하여 출력하는 시스템을 설계해보자

## 문제 이해 및 설계 범위 확정

---

어떤 검색어 자동완성 시스템을 만들지 고민해야 한다.

- 사용자가 입력하는 단어가 자동완성될 검색어의 첫 부분인지 중간 부분도 가능한지
- 몇 개의 자동완성 검색어가 나와야 하는지
- 자동완성 검색어를 고르는 기준이 어떻게 되는지
- 맞춤법 검사 기능을 제공하는지
- 어떤 언어를 지원하는지
- 대문자 또는 특수문자 처리를 지원하는지
- 사용자 규모

### 요구사항

- 빠른 응답 속도: 자동완성 검색어는 빠르게 표시되어야 한다.
- 연관성: 자동완성 검색어는 사용자가 입력한 단어와 연관되어야 한다.
- 정렬: 시스템 계산 결과는 인기도 등의 순위 모델에 의해 정렬되어야 한다.
- 규모 확장성: 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.
- 고가용성: 시스템 일부에 장애가 발생하거나, 느려지거나, 네트워크 버그가 생기더라도 시스템은 계속 사용 가능해야 한다.

### 개략적 규모 추정

- DAU는 천만 명
- 한 사용자는 매일 10건의 검색을 수행
- 검색어를 입력할 때 평균적으로 20바이트의 데이터를 입력
    - 인코딩은 ASCII 사용 → 1문자 = 1바이트
    - 질의문은 평균적으로 4개의 단어로 이루어진다고 가정, 1개의 단어는 평균적으로 5글자
    - 질의 당 평균은 20 바이트
- 검색창에 글자를 입력할 때마다 클라이언트가 검색어 자동완성 서버에게 요청을 보낸다 → 1회 검색 당 20번의 요청이 백엔드로 전달됨
- 초당 24000건의 질의가 발생한다 → (천만 사용자 * 10 질의 * 20자 / 24시간 / 3600초)
- 최대 QPS = QPS * 2 = 48000
- 검색어의 20%는 신규 검색어라고 가정한다. → 0.4GB (천만 사용자 * 10 질의 * 20자 * 20%)

## 개략적 설계안 제시 및 동의 구하기

---

시스템은 두 부분으로 나뉜다.

- 데이터 수집 서비스: 사용자가 입력한 검색어를 실시간으로 수집하는 시스템 → 데이터가 많아 실시간 시스템에 적합하지 않다. 추후 수정
- 질의 서비스: 주어진 질의에 5개의 인기 검색어를 정렬해 내놓는 서비스

### 데이터 수집 서비스

질의문과 사용 빈도를 저장하는 빈도 테이블이 있다고 가정

사용자가 데이터를 검색하면 할수록 빈도가 채워지게 된다.

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/9490fdc8-ce97-498c-a9d6-f0043a605c0d)

### 질의 서비스

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/dfe34a8c-f95e-4f40-a2f1-44258053c9b9)

query: 질의문을 저장하는 필드

frequency: 질의문이 사용된 빈도를 저장하는 필드

**top 5는 위의 빈도 테이블에 기록된 수치를 바탕으로 계산하게 된다.**

```sql
select * from frequency_table
where query like 'prefix%'
order by frequency desc
limit 5;
```

**데이터가 많아지면 병목이 발생할 수 있다.**

## 상세 설계

---

이제 위의 시스템을 상세하게 설계하면서 개선해보자

### 트라이 자료구조

RDB는 가장 인기 많은 5개의 질의를 골라내기에 효율적인 저장소가 아니다.

트라이를 통해서 문제를 해결할 수 있다.

**트라이는 문자열을 간략하게 저장할 수 있는 자료구조이다.**

- 트라이는 트리 형태의 자료구조
- 트리의 루트 노드는 빈 문자열
- 각 노드는 글자 1개를 저장하며, 26개의 자식 노드를 가질 수 있다.
- 각 트리 노드는 하나의 단어 또는 접두어 문자열을 나타낸다.

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/b4e7bcaf-4e49-4ac0-b0db-af514f6d021f)

**노드에 문자열을 저장하고 이용 빈도에 따라 정렬된 결과를 내놓기 위해서는 노드에 빈도 정보까지 저장할 필요가 있다.**

> 용어 정리
p: 접두어(prefix)의 길이
n: 트라이 안에 있는 노드 개수
c: 주어진 노드의 자식 노드 개수
> 

가장 많이 사용된 질의어 k개를 찾는 방법

- 접두어를 표현하는 노드를 찾는다. 시간 복잡도 O(p)
- 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다. 유효한 검색 문자열을 구성하는 노드가 유효 노드이다. 시간 복잡도 O(c)
- 유효 느드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다. 시간 복잡도 O(clogc)

책 232p 예시 참고

결과적으로 해당 알고리즘의 시간 복잡도는 O(p) + O(c) + O(clogc)이다.

**최악의 경우 모든 트라이를 다 탐색 할 수도 있음**

이를 피하기 위한 방법

1. 접두어의 최대 길이 제한
    - 사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없으므로 최대 길이를 적절하게 제한할 수 있다.
    - 제한한다면 접두어 노드를 찾는 단계의 시간 복잡도는 O(p)에서 O(작은 상수값) = O(1)이 된다.
2. 각 노드에 인기 검색어를 캐싱
    - 인기 검색어를 각 노드에 저장해두면 전체 트라이를 검색하는 일을 방지할 수 있다.
    - 이렇게 캐시해두면 시간 복잡도는 낮아지지만 공간 복잡도가 커지게 되는 단점 존재
    - 그러나 빠른 응답속도가 중요할 때는 이 정도 저장 공간은 희생할 가치가 있음

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/9855dbe8-a81b-419b-9855-04497caa93ea)

이러한 최적화 기법을 도입한 시간 복잡도는 다음과 같음

1. 접두어 노드를 찾는 시간 복잡도 O(1)
2. 최고 인기 검색어를 찾는 시간 복잡도 O(1) → 캐싱했기 때문에

결과적으로 전체 알고리즘 복잡도가 O(1)로 바뀐다.

### 데이터 수집 서비스

실시간으로 데이터를 수정하는 방법은 2가지 문제로 그렇게 좋지 못함

- 매일 수천만의 질의가 입력되는데 그때마다 트라이를 갱신하면 질의 서비스 느려짐
- 일단 트라이가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않음 → 자주 갱신할 필요 없음

트라이를 만드는데 쓰이는 데이터는 보통 데이터 분석 서비스 또는 로깅 서비스로부터 온다.

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/5f5d88b5-6387-4583-967c-fb7eccc0a5f0)

**데이터 분석 서비스 로그**

**데이터 분석 서비스 로그에는 검색창에 입력된 질의에 관한 원본 데이터가 보관된다.**

데이터 추가만 발생하고 인덱스가 걸리지 않음

**로그 취합 서버**

데이터 분석 서비스로부터 나오는 로그는 양이 엄청나고 데이터 형식이 제각각인 경우가 많음

데이터를 잘 취합해야 한다.

실시간성이 중요하면 자주 취합을 할것이고 그게 아니라면 적절한 시기마다 취합할것이다.

**취합된 데이터**

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/516d60f8-32f4-4e36-a975-ad15750a9b0b)

이러한 형식으로 데이터를 취합한다.

**작업 서버**

주기적으로 비동기 작업을 실행하는 서버 집합이다. 트라이 자료구조를 만들고 트라이 데이터베이스에 저장하는 역할을 담당한다.

**트라이 캐시**

분산 캐시 시스템으로 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높이는 역할을 수행

매주 트라이 데이터베이스의 스냅샷을 가져와서 갱신

**트라이 데이터베이스**

지속성 저장소이다.

1. 문서 저장소: 새 트라이를 매주 생성하므로 주기적으로 트라이를 직렬화하여 데이터베이스에 저장 가능 → 몽고 디비를 활용하면 이런 데이터 편리하게 관리 가능하다.
2. 키-값 저장소: 트라이는 다음과 같은 방법으로 해시 테이블 형태로 변환 가능
    - 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
    - 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/cd31d44d-615a-4bd4-ab2a-bfb67e58a1c6)

### 질의 서비스

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/03788282-4969-4e75-9418-e45e880930ea)

1. 검색 질의가 로드밸런서로 전송된다.
2. 로드밸런서는 해당 질의를 API 서버로 보낸다.
3. API 서버는 트라이 캐시에서 데이터를 가져와 요청에 대한 자동완성 검색어 제안 응답을 구성한다.
4. 데이터가 트라이 캐시에 없는 경우 데이터를 DB에서 가져와 캐시를 채운다.

질의 서비스는 빨라야 하기 때문에 다음과 같은 최적화 방법 고민 가능

- AJAX 요청: 요청을 보내고 받기 위한 새로고침 과정이 필요없어 빠르다.
- 브라우저 캐싱: 자동완성 검색어 제안 결과는 자주 바뀌지 않으므로 브라우저 캐시에 넣어두면 후속 질의는 바로 가져올 수 있음 → cache-control 헤더를 통해서 제안된 검색어 브라우저 캐싱 가능
- 데이터 샘플링: 모든 질의를 로깅해두면 CPU 자원과 저장공간 낭비가 심하다 → 데이터 샘플링 방법이 유용하다.

### 트라이 연산

**트라이 생성**

트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 데이터베이스로부터 취합된 데이터를 이용

**트라이 갱신**

1. 매주 한 번 갱신하는 방법: 새 트라이를 만들고 교체
2. 트라이의 각 노드를 갱신하는 방법: 성능이 좋지 않지만 트라이가 작다면 충분히 사용 가능하다.

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/1990a756-c4fc-44fe-93c1-d7d9eff14ccb)

**검색어 삭제**

쓸모없는 검색어는 자동완성 결과에서 제거해야 한다.

트라이 앞에 필터 계층을 두어 부적절한 질의가 들어가지 않도록 막아줘야 한다.

### 저장소 규모 확장

첫 글자 기준으로 샤딩하는 방법으로 저장소 규모 확장 가능

- 두 대의 서버라면 a-m까지는 첫 번째 서버에 나머지는 두 번째 서버에 저장할 수 있음
- 세 대의 서버라면 a-i까지 첫 번째, j-r까지 두 번째, 나머지는 세 번째 서버에 저장 가능

이 방법으로 26대의 서버까지 확장 가능하다.

추가적으로 확장하기 위해서는 샤딩을 계층적으로 해야된다.

다만 이 방법은 단어의 시작하는 알파벳이 고르게 분포되어 있지 않아 균등하게 데이터가 배분되기 어려운 단점이 있다.

검색어 대응 샤드 관리자를 도입하여 검색어 양을 비교해서 적절한 샤드를 만드는 방법을 채택할 수 있음

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/76324605-4d88-4f1e-bfc8-fdfe1be10954)

## 마무리

---

추가적으로 고민해볼 문제들

- 다국어 지원 → 유니코드를 활용해야 한다.
- 국가별 인기 검색어 순위가 다른 경우 → 트라이를 CDN에 저장하는 방법 고려 가능
- 실시간으로 변하는 검색어 추이 반영하는 방법
    - 샤딩을 통해 작업 대상 데이터 양을 줄이기
    - 순위 모델을 바꾸어 최근 검색어에 높은 가중치를 주기
    - 데이터가 스트림 형태로 올 수 있기 때문에 카프카, 아파치 스파크 스트리밍, 하둡 등 고려 가능
