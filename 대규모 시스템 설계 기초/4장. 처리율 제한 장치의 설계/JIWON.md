# 4장. 처리율 제한 장치의 설계

---

처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스는 주당 5회 이상 리워드를 요청할 수 없다.

처리율 제한 장치를 사용했을 때 장점

- DoS(Denial of Service) 공격에 의한 자원 고갈 방지: 대부분 IT 기업들은 처리율 제한 장치 보유 → 추가 요청을 처리하지 않음으로 DoS 공격을 방지한다.
- 비용 절감: 추가 요청에 대한 처리를 제한함으로 서버를 더 많이 안둬도 되고 중요 API에 더 많은 자원 할당 가능 → 서드 파티 API를 사용하여 사용료를 지불하는 경우 활용하면 좋다
- 서버 과부하 방지: 봇 또는 잘못된 이용 패턴으로 유발된 트래픽을 걸러내는데 처리율 제한 장치 활용 가능

## 1단계 문제 이해 및 설계 범위 확정

---

처리율 제한 장치를 구현하는 데 여러 알고리즘 사용 가능

면접시 질문 또는 고려해야할 점

- 클라이언트 사이드 제한 장치, 서버 사이드 제한 장치
- 처리율 제한 타겟 → API, IP Address, User ID 등
- 시스템 전체적인 규모
- 단일 환경, 분산 환경
- 처리율 제한 서비스가 독립적인 서비스인지 애플리케이션 코드에 포함되는지
- 유저에게 제한 여부를 알리는지

### 요구사항

- 설정된 처리율을 초과하는 요청은 정확하게 제한
- 낮은 응답시간: 처리율 제한 장치로 인해 HTTP 응답 시간에 나쁜 영향을 주면 안 된다.
- 적은 메모리 사용
- 분산형 처리율 제한: 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
- 예외 처리: 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.
- 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주면 안된다.

## 2단계 개략적 설계안 제시 및 동의 구하기

---

### 처리율 제한 장치는 어디에 둘 것인가?

- 클라이언트: 클라이언트 요청은 위변조가 가능하여 통제하기 어려움
- 서버: 서버에 들어오는 요청은 위변조가 안되어 가능
- 미들웨어: 처리율 제한 장치를 담당하는 미들웨어를 만들어 미들웨어 → API 서버로 가게 만든다.

**요청이 여러번 전송되면 미들웨어에서 이를 감지하고 429 에러를 내보내 API 서버로 요청이 가지 않게 만들 수 있다.**

**MSA로 설계된 경우 처리율 제한 장치는 보통 API 게이트웨이에서 구현된다.**

**API 게이트웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 위탁관리형 서비스이다.**

회사의 현재 기술 스택이나 여러 상황들을 고려하여 처리율 제한 장치의 위치를 정하면 된다.

- 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택을 점검 → 프로그래밍 언어가 서버 측 구현을 지원하기에 충분할 정도로 효율이 높은지 확인
- 알맞은 처리율 제한 알고리즘 찾기 → 서버 측에서 직접 구현시 알고리즘 자유, API 게이트웨이를 제공받을시 선택지 제한
- 이미 현재 서비스가 MSA인 경우 API 게이트웨이가 이미 설계되어 있을 수 있어 여기서 처리율 제한 기능을 추가해야 됨
- 직접 처리율 제한 서비스를 만드는 것은 시간이 들기 때문에 시간이 부족하거나 인력이 부족하다면 상용 API 게이트웨이를 만드는게 좋은 방법일 수 있음

### 처리율 제한 알고리즘

- 토큰 버킷 알고리즘
    - 간단하고 보편적으로 많이 사용한다.
    - 토큰 버킷은 지정된 용량을 가진 컨테이너
    - 버킷에서 주기적으로 토큰이 채워진다. → 다 채워진 경우 새로 생성된 토큰은 버려짐
    - 각 요청이 처리될 때 하나의 토큰을 사용한다.
        - 버킷에 토큰이 있는 경우 토큰 하나를 사용함
        - 버킷에 토큰이 없는 경우 요청을 버려진다.
    - 2개의 인자를 받는다.
        - 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
        - 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는지
    - 유저마다 처리율을 제한하는 경우 → 유저마다 토큰 버킷을 생성해준다.
    - IP 주소별로 처리율을 제한하는 경우 → IP 주소마다 버킷을 할당
    - 시스템의 처리율을 제한하는 경우 → 모든 요청이 하나의 버킷을 할당
    - 장점
        - 구현이 쉽다.
        - 메모리 효율적으로 사용
        - 짧은 시간 집중되는 트래픽 처리 가능
    - 단점
        - 인자를 튜닝하는 것이 쉽지 않음
- 누출 버킷 알고리즘
    - 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정
    - FIFO 큐로 구현
        - 요청이 도착하면 큐가 가득 차 있는지 확인한다. 비어있다면 큐에 요청을 추가
        - 큐가 가득 차 있다면 새 요청은 버린다.
        - 지정된 시간마다 큐에서 요청 꺼내서 처리
    - 2개의 인자를 받는다.
        - 버킷 크기: 큐 사이즈
        - 처리율: 지정된 시간 당 몇 개의 항목을 처리할지 지정
    - 장점
        - 큐 크기가 고정되어 메모리 측면에서 효율적
        - 고정된 처리율로 안정적 출력이 필요할 때 좋음
    - 단점
        - 단 시간에 트래픽이 몰리는 경우 최신 요청이 버려지게 된다.
        - 인자들을 튜닝하기 어렵다.
- 고정 윈도우 카운터 알고리즘
    - 타임라인을 고정된 간격의 윈도우로 나누고 윈도우에 카운터를 붙인다.
    - 요청이 접수될 때마다 카운터 값 1씩 증가
    - 카운터 값이 임계치에 도달하면 새로운 요청은 새 윈도우가 열릴 때까지 버려진다.
        
  ![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/ebcd565e-e0a2-4176-9333-983ba70bd3f5)
        
    - 문제점: 윈도우의 경계 부분에 순간적으로 트래픽이 집중될 경우 더 많은 요청이 처리될 수 있음
        
  ![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/569f7734-693f-4634-a3e7-6e3331008804)
        
    - 장점
        - 메모리 효율이 좋음
        - 이해하기 쉬움
        - 특정한 트래픽 패턴을 처리하기 적합
    - 단점
        - 윈도우 경계 부분에 트래픽이 몰릴 경우 더 많은 요청을 처리하게 된다.
- 이동 윈도우 로깅 알고리즘
    - 고정 윈도우 카운터 알고리즘의 문제를 해결한 알고리즘
    - 타임스탬프를 추적한다. → Redis의 sorted set과 같은 캐시에 보관
    - 새 요청이 오면 만료된 타임스탬프 제거
    - 새 요청의 타임스탬프를 로그에 추가
    - 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달, 그렇지 않으면 처리를 거부
    - 장점
        - 정교한 알고리즘 → 요청의 개수는 시스템 처리율 한도를 넘지 않음
    - 단점
        - 다량의 메모리 사용 → 거부된 요청의 타임스탬프도 보관하기 때문에
- 이동 윈도우 카운터 알고리즘
    - 고정 윈도우 카운터 알고리즘 + 이동 윈도우 로깅 알고리즘 결합한 방식
    
  ![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/5542b736-fb15-488c-bb12-9408720d6525)
    
    - 장점
        - 짧은 시간에 몰리는 트래픽에 잘 대응한다.
        - 메모리 효율이 좋다.
    - 단점
        - 추정치를 계산하기 때문에 다소 느슨한 알고리즘 → 심각한 문제는 아님

### 개략적인 아키텍처

처리율 제한 알고리즘의 기본 아이디어: 얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 추적 대상별로 두고 카운터 값이 한도를 넘어가면 요청을 거부한다.

레디스를 활용하면 좋다.

- INCR: 카운터 값을 1씩 증가시키는 용도
- EXPIRE: 카운터에 타임아웃 값 설정하여 자동으로 만료되도록 설정

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/28a8a469-a0e0-404b-be62-52c9d8fbf0b1)

동작 방식

- 클라이언트가 요청을 보낸다.
- 처리율 제한 미들웨어가 레디스를 통해 카운터를 가져옴
    - 카운터가 초과한 경우: 요청 거부
    - 카운터가 초과하지 않은 경우: 요청 허용 및 카운터 값 1 증가

## 3단계 상세 설계

---

### 처리율 제한 규칙

각자 알맞은 처리율 제한 규칙이 존재하고 이런 규칙들은 보통 설정 파일 형태로 디스크에 저장된다.

### 처리율 한도 초과 트래픽의 처리

한도 제한에 걸린 경우 HTTP 429 응답을 클라이언트에게 보낸다.

경우에 따라 응답 메시지를 큐에 보관하여 나중에 처리할 수도 있음

- 처리율 제한 장치가 사용하는 HTTP 헤더
    - 클라이언트가 본인의 요청이 처리율 제한에 걸리고 있는지 확인할 수 있게 사용하는 헤더
    - X-Ratelimit-Remaining : 윈도우 내에 남은 처리 가능 요청의 수
    - X-Ratelimit-Limit : 매 윈도우마다 클라이언트가 전송할 수 있는 요청의 수
    - X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
- 429 응답을 보낼 때 X-Ratelimit-Retry-After를 같이 보내야한다.

### 상세 설계

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/b8b95501-5ff8-4311-af8b-ea59cfa491c2)

- 처리율 제한 규칙은 디스크에 보관, 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 보관
- 클라이언트가 요청을 보내면 처리율 제한 미들웨어에 도달
- 미들웨어는 캐시에서 제한 규칙 가져오고 규칙에 따라 알맞은 행동
    - 요청이 제한에 안걸리면 API 서버로 보낸다
    - 요청이 제한에 걸리면 429 응답을 보낸다.

### 분산 환경에서의 처리율 제한 장치의 구현

분산 환경에서 고려할 점은 2가지가 있다.

- 경쟁 상태
    - 병행 환경에서 경쟁 상태가 만들어질 수 있다.
    - 락을 통해 해결 → 시스템 성능이 안좋아짐
    - 루아 스크립트, 레디스 sorted set 활용하여 해결하는 방법도 있음
- 동기화
    - 처리율 제한 장치 서버가 여러 대일 수 있다. → 동기화 필요함
    - 고정 세션을 활용하는 방식 → 비추: 확장하기 어렵고 유연하지 않음
    - 레디스와 같은 중앙 장치를 활용하는 것을 추천!

### 성능 최적화

여러 데이터 센터를 지원하는 경우: edge server를 이용하여 사용자에게 물리적으로 가장 가까운 edge server에 트래픽 전달

제한 장치간 데이터 동기화할 때 일관성 모델 활용 (자세한 내용 6장 참고)

### 모니터링

- 처리율 제한 알고리즘이 효율적인지
- 처리율 제한 규칙이 효과적인지

모니터링을 통해 적절한 처리율을 설정하도록 하자

## 4단계 마무리

---

더 고려해볼 사항

- hard, soft 처리율 제한
    - hard: 요청의 개수는 임계치를 절대 넘을 수 없다.
    - soft: 요청의 개수는 잠시 동안 임계치를 넘을 수 있다.
- 다양한 계층의 처리율 제한
    - Application Layer가 아닌 다른 계층에서도 처리율 제한이 가능하다.
    - Iptables를 사용하면 Network Layer에서 처리율 제한 가능
- 처리율 제한을 회피하는 방법
    - 클라이언트 측 캐시를 사용하여 API 호출을 줄인다.
    - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 한다.
    - 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 우아하게 복구
    - 재시도는 충분한 백오프 시간
