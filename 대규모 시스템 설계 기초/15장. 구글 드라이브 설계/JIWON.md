# 15장. 구글 드라이브 설계

---

## 문제 이해 및 설계 범위 확정

---

- 가장 중요하게 지원해야 할 기능: 파일 업로드 및 다운로드, 파일 동기화, 알림
- 지원 단말: 앱, 웹
- 파일 암호화 여부
- 파일 크기 제한
- 사용자 (DAU)

다음 기능을 설계한다.

- 파일 추가, 가장 쉬운 방법은 파일을 구글 드라이브 안으로 떨구는 것
- 파일 다운로드
- 여러 단말에 파일 동기화 → 한 단말에 파일을 추가하면 다른 단말도 자동으로 동기화
- 파일 갱신 이력 조회
- 파일 공유
- 파일 편집 및 삭제 시 알림

비기능적 요구사항

- 안정성
- 빠른 동기화 속도
- 네트워크 대역폭
- 규모 확장성
- 높은 가용성

### 개략적 추정치

- 가입 사용자는 5000만, DAU 1000만
- 모든 사용자는 10GB 무료 저장공간 할당
- 매일 사용자가 평균 2개의 파일 업로드 가정 → 파일의 평균 크기 500KB
- 읽기, 쓰기 비율 = 1:1
- 필요한 저장공간 = 5000만 * 10GB = 500 페타바이트
- 업로드 API QPS = 1000만 사용자 * 2회 업로드 / 24시간 / 3600초 = 240
- 최대 QPS = QPS * 2 = 480

## 개략적 설계안 제시 및 동의 구하기

---

1대의 서버로 시작해서 설계를 점점 발전시켜보자

1대의 서버는 다음의 기능을 한다.

- 파일을 올리고 다운로드 하는 과정을 처리할 웹 서버
- 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스
- 파일을 저장할 저장소 시스템, 파일 저장을 위해 1TB의 공간을 사용한다.

### API

3가지 API가 필요하다.

1. 파일 업로드 API

두 종류의 업로드를 지원

- 단순 업로드: 파일 크기가 작을 때 사용한다.
- 이어 올리기: 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각될 때 사용

이어 올리기 API 예시

`api.sample.com/files/upload?uploadType=resumable`

인자

- `uploadType=resumable`
- data: 업로드할 로컬 파일

이어 올리기 절차

- 이어 올리기 URL을 받기 위한 최초의 요청 전송
- 데이터를 업로드하고 업로드 상태 모니터링
- 업로드에 장애가 발생하면 장애 발생시점부터 업로드 재개
1. 파일 다운로드 API

`api.sample.com/files/download`

인자

- path: 다운로드할 파일의 경로
1. 파일 갱신 히스토리 API

`api.sample.com/files/list_revisions`

인자

- path: 갱신 히스토리를 가져올 파일의 경로
- limit: 히스토리 길이의 최대치

모든 API는 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용해야 한다.

### 한 대 서버의 제약 극복

파일은 결국엔 다 차게 된다.

파일이 다 찼을 때 해결 방법으로는 샤딩이 있다.

→ `user_id` 기준으로 샤딩하는 방법을 고려할 수 있다.

아니면 **AWS S3를 사용하는 방법을 고려할 수 있다.**

**S3는 다중화를 지원하고 같은 지역에서 다중화, 여러 지역에 걸쳐 다중화 등 여러 상황에서 다중화가 가능하다.**

→ 데이터 손실을 막고 가용성을 최대한 보장할 수 있다.

더 고려할 점

- 로드밸런서: 부하 분산 및 특정 서버 장애 시 우회
- 웹 서버: 로드밸런서로 더 많은 웹 서버 추가 가능
- 메타데이터 데이터베이스: 데이터베이스를 파일 저장 서버와 분리하여 SPOF를 회피 + 다중화 및 샤딩
- 파일 저장소: S3 사용

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/5bf4183b-7c9e-44a6-8758-ae6449f7d14b)

### 동기화 충돌

때때로 동기화 충돌이 발생할 수 있다. → 동시 업데이트

사용할 수 있는 전략 → 먼저 처리되는 변경은 성공으로 보고, 나중에 처리되는 변경은 충돌로 처리

동기화 충돌이 발생한 시점에 시스템에는 파일이 2가지 존재 (로컬 파일, 서버 최신 파일)

→ 파일을 합칠지 아니면 둘 중 하나를 선택할지 결정해야 된다.

### 개략적 설계안

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/814d2430-0645-48a5-aa60-ae09dea43acf)

- 사용자 단말: 앱, 웹 등 사용자 클라이언트
- 블록 저장소 서버: 파일 블록을 클라우드 저장소에 업로드하는 서버이다. 파일을 여러개의 블록으로 나누어 저장하며, 블록에는 고유한 해시값을 할당한다. → 해시값은 메타데이터 데이터베이스에 저장된다. 파일을 재구성하려면 블록들을 원래 순서로 합쳐야 한다.
- 클라우드 저장소: 파일은 블록 단위로 나눠져 클라우드 저장소에 보관된다.
- 아카이빙 저장소: 오랫동안 사용되지 않은 비활성 데이터를 저장하기 위한 컴퓨터 시스템
- 로드밸런서: 요청을 모든 API 서버로 고르게 분산하는 구실
- API 서버: 파일 업로드를 제외한 거의 모든 요청을 담당하는 서버
- 메타데이터 데이터베이스: 사용자, 파일 정보, 블록 등 메타데이터 정보를 관리하는 DB
- 메타데이터 캐시: 성능을 높이기 위해 자주 쓰이는 메타데이터는 캐시
- 알림 서비스: 특정 이벤트가 발생했음을 클라이언트에 알려주는 서버 (pub/sub 구조)
- 오프라인 사용자 백업 큐: 클라이언트가 접속했을 때 동기화될 수 있도록 도와주는 큐

## 상세 설계

---

### 블록 저장소 서버

파일 업데이트 최적화 방법

- 델타 동기화: 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화
- 압축: 블록 단위로 압축해두면 데이터 크기를 많이 줄일 수 있다.

**블록 저장소 서버는 클라이언트가 보낸 파일을 블록 단위로 나누고, 각 블록에 압축 알고리즘을 적용하고, 암호화까지 담당한다. + 수정된 블록만 전송해야 된다.**

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/7bfd0f25-14ee-45ec-940d-005bf9db95cd)

- 주어진 파일을 작은 블록들로 분할
- 블록을 압축
- 블록 암호화
- 클라우드 저장소로 전송

델타 동기화 전략은 수정된 블록만 클라우드 저장소로 전송하면 된다.

2가지 방법을 통해 네트워크 사용량을 줄일 수 있다.

### 높은 일관성 요구사항

강한 일관성 모델을 기본으로 지원해야 한다.

→ 같은 파일이 단말이나 사용자에 따라 다르게 보이면 안된다.

메모리 캐시는 강한 일관성을 달성하기 위해 다음 사항을 보장해야 한다.

- 캐시에 보관된 사본과 데이터베이스에 있는 원본이 일치한다.
- 데이터베이스에 보관된 원본에 변경이 발생하면 캐시의 사본을 무효화한다.

RDB는 ACID를 보장하므로 강한 일관성을 보장하기 쉽다.

### 메타데이터 데이터베이스

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/71e6426b-33ba-4f43-9b44-c64eba0bf78f)

- user: 유저 정보를 담는 테이블
- device: 단말 정보가 저장되는 테이블
- namespace: 사용자의 루트 디렉토리 정보가 보관된다.
- file: 파일의 최신 정보가 보관된다.
- file_version: 파일의 갱신 이력이 보관되는 테이블이다. 이 테이블에 보관되는 레코드는 모두 읽기 전용
- block: 파일 블록에 대한 정보를 보관하는 테이블

### 업로드 절차

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/0f37a1d8-7ff7-4f85-bda2-e24ff1d4a115)

2개 요청이 병렬적으로 전송된 상황

- 파일 메타데이터 추가
    1. 클라이언트가 새 파일의 메타데이터를 추가하기 위한 요청 전송
    2. 새 파일의 메타데이터를 DB에 저장하고 업로드 상태를 대기 중으로 변경
    3. 새 파일이 추가되었음을 알림 서비스에 통지
    4. 알림 서비스는 관련된 클라이언트에게 업로드되고 있음을 알림
- 파일을 클라우드 저장소에 업로드
    1. 클라이언트가 파일을 블록 저장소에 업로드
    2. 블록 저장소는 파일을 블록으로 나누고 여러 작업을 수행한 뒤 클라우드 저장소로 전송
    3. 업로드가 끝나면 클라우드 스토리지 완료 콜백을 호출 → 콜백 호출은 API로 전송됨
    4. 메타데이터 DB에 기록된 해당 파일의 상태를 완료로 변경
    5. 알림 서비스에 파일 업로드 끝남을 알림
    6. 알림 서비스는 관련된 클라이언트에게 파일 업로드가 끝났음을 알림

### 다운로드 절차

![image](https://github.com/ZI-won-ZONE-ha/CS_JONGJIBU/assets/88527476/7a87fe3a-9ca7-4c8c-aeb5-af9d92b75afd)

1. 알림 서비스가 클라이언트에게 파일 변경을 알림
2. 클라이언트가 새로운 메타데이터 요청
3. API 서버가 메타데이터 DB에 새 메타데이터 요청
4. 클라이언트에게 메타데이터 반환
5. 클라이언트는 메타데이터를 받는 즉시 블록 다운로드 요청
6. 블록 저장소 서버가 클라우드 저장소에서 블록을 다운받고 이를 클라이언트에게 전송

### 알림 서비스

파일의 일관성 유지를 위해 파일이 변경되는 순간 바로 알림을 보내야 한다.

→ 충돌이 발생할 가능성을 줄여야 한다.

알림 서비스의 선택지

- 롱 폴링
- 웹소캣

롱 폴링을 사용하여 설계한다.

- 알림 서비스와 양방향 통신이 필요하지 않기 때문에 웹소캣 사용 이유가 적음

### 저장소 공간 절약

- 중복 제거: 중복되는 파일 블록을 해시 값 비교를 통해 제거한다.
- 지능적 백업 전략 도입
    - 한도 설정: 보관할 파일 버전 개수에 상한을 둔다.
    - 중요한 버전만 보관
- 자주 쓰이지 않는 데이터는 아카이빙 저장소로 옮긴다.

### 장애 처리

- 로드밸런서 장애: 로드밸런서에 문제가 생기면 부 로드밸런서가 활성화되어 트래픽을 이어 받아야 한다. 로드밸런서끼리는 박동 신호를 보내 서로 상태를 확인함
- 블록 저장소 서버 장애: 다른 서버가 작업을 이어 받아야 한다.
- 클라우드 저장소 장애: S3는 여러 지역에 다중화되기 때문에 이를 활용
- API 서버 장애: 로드밸런서가 장애난 서버로 트래픽을 보내면 안 된다.
- 메타데이터 캐시 장애: 캐시 서버도 다중화한다.
- 메타데이터 데이터베이스 장애: 주, 부에 따라 하던대로 장애 대처
- 알림 서비스 장애: 롱 폴링 연결을 복구하는 것이 조금 오래 걸릴 수 있음
- 오프라인 사용자 백업 큐 장애: 큐도 다중화하여 장애 방지

## 마무리

---

높은 수준의 일관성, 낮은 네트워크 지연, 빠른 동기화를 요구하는 시스템을 구축해야 한다.

추가적으로 고민할 사항들

- 빠른 업로드를 위해 분할 압축 암호화 로직을 클라이언트에 둔다. → 플랫폼 별로 구축해야 된다.
    - 클라이언트는 해킹 가능성이 있으므로 좋은 선택지는 아닐 수 있음
- 접속 상태 관리
