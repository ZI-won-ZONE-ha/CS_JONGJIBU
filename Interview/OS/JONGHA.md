# 운영체제와 시스템 콜

### 운영체제란 무엇인지 설명해 주세요.

**운영체제의 역할**

컴퓨터 시스템의 자원을 효율적으로 관리하며, 그에 대한 역할은 리소스 매니저(효율적 관리), 가상화, concurrency를 해결한다. persistence를 가능하게 한다. 

### Process와 Thread의 차이를 설명해 주세요.

**프로세스** : 프로그램을 메모리 상에서 실행중인 작업

**스레드** : 프로세스 안에서 실행되는 작업의 단위 

프로세스 내에 여러 쓰레드 할당할 수 있다. 하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드 같이 생성

**프로세스는 자신만의 고유 공간과 자원을 할당받아 사용**하는데 반해, **스레드는 다른 스레드와 공간, 자원을 공유하면서 사용**하는 차이가 존재함. 스레드는 Stack만 따로 할당 받고 나머지 영역은 서로 공유

**프로세스 메모리 구조**

- **Code** : 코드 자체를 구성하는 메모리 영역(프로그램 명령)
- **Data** : 전역변수, 정적변수, 배열 등
    - 초기화 된 데이터는 data 영역에 저장
    - 초기화 되지 않은 데이터는 bss 영역에 저장
- **Heap** : 동적 할당 시 사용 (new(), malloc() 등)
- **Stack** : 지역변수, 매개변수, 리턴 값 (임시 메모리 영역)

### 멀티 프로세스와 멀티 쓰레드의 차이점을 알려주세요

- 멀티 프로세스
    - 독립적인 메모리 공간.
    - context switching 비용 많이 든다.  프로세스 간 통신 (IPC)은 쓰레드 간 통신보다 느리고 복잡
- 멀티 쓰레드
    - 공유한 메모리 공간, 프로세스보다 메모리 사용량이 적으므로, 더 많은 요청을 더 적은 자원으로 처리
    - 동시성 이슈에 주의 하여야 한다. 한 쓰레드에서의 오류가 전체 프로세스에 영향

### Context Switching은 무엇인지 설명해 주세요.

CPU가 현재 작업 중인 프로세스에서 다른 프로세스로 넘어갈 때 지금까지의 프로세스의 상태를 저장하고, 새 프로세스의 저장된 상태를 다시 적재하는 작업을 Context Switch(문맥 교환)이라 한다. (프로세스의 정보는 PCB에 저장된다.)

### **언제 발생하는가?**

Context Switch가 발생하는 경우는 멀티태스킹, 인터럽트 핸들링, 사용자 모드와 커널 모드 간의 전환까지, 크게 3가지가 존재한다.

- 멀티태스킹(Multitasking)
    - 실행 가능한 프로세스들이 운영체제의 스케줄러에 의해 조금씩 번갈아가며 수행되는 것을 말한다.
    - 번갈아 가며 프로세스가 CPU를 할당 받는데 이때 Context Switching 한다.
    - 사용자가 체감하기 힘든 속도로 Context Switching되며 프로세스가 처리되기 때문에 동시에 처리되는 것처럼 느껴진다.
- 인터럽트 핸들링(Interrupt handling)
    - 인터럽트란 컴퓨터 시스템에서 예외 상황이 발생했을때 CPU에게 알려 처리할 수 있도록 하는 것을 말한다.
    - 인터럽트가 발생하면 Context Switching한다.
    - I/O request : 입출력 요청
    - time slice expired : CPU 사용시간이 만료
    - fork a child : 자식 프로세스 생성
    - wait for an interrupt : 인터럽트 처리 대기
- 사용자와 커널 모드 전환(User and kernel mode switching)
    - 사용자와 커널 모드 전환은 Context Switch가 필수는 아니지만 운영체제에 따라 발생할수 있다

### **Context Switching 과정**


1. 요청 발생: 인터럽트 또는 트랩에 의한 요청이 발생.(트랩은 소프트웨어 인터럽트)
2. PCB에 저장: 운영체제는 현재 실행중인 프로세스(P0)의 정보를 PCB에 저장.
3. CPU 할당: 운영체제는 다음 프로세스(P1)의 정보를 PCB에서 가져와 CPU를 할당.

위 과정을 반복적으로 수행한다. Context Switching하는 동안 CPU는 아무일도 하지않는 시간이 발생하는데 이를 오버헤드(Overhead)라 하고 오버헤드가 잦아지면 성능이 떨어질수 있다.

### PCB 과 뭔가요?

모든 프로세스가 생성이 되면, 해당 프로세스의 중요한 정보를 담고 있는 자료 구조가 생기는 데 이를 PCB라고 한다. Program counter, register, open file 에 대한 정보를 가지고 있다.  → 이는 커널의 데이터 구조에 생긴다.  

### **PCB가 왜 필요한가요?**

CPU에서는 프로세스의 상태에 따라 교체작업이 이루어진다. (interrupt가 발생해서 할당받은 프로세스가 waiting 상태가 되고 다른 프로세스를 running으로 바꿔 올릴 때) 이때, **앞으로 다시 수행할 대기 중인 프로세스에 관한 저장 값을 PCB에 저장해두는 것**이다.

### **PCB는 어떻게 관리되나요?**

Linked List 방식으로 관리된다.

PCB List Head에 PCB들이 생성될 때마다 붙게 된다. 주소값으로 연결이 이루어져 있는 연결리스트이기 때문에 삽입 삭제가 용이하다.

즉, 프로세스가 생성되면 해당 PCB가 생성되고 프로세스 완료 시 제거된다.

이렇게 수행 중인 프로세스를 변경할 때, CPU의 레지스터 정보가 변경되는 것을 Context Switching이라고 한다.

### 동시성 - Concurrent vs Parallel

- **Concurrent** : 어떤 Job 여러 개가 동시에 처리된다는 개념 (멀티)
- **Parallel** : 어떤 하나의 Job을 쪼개서 여러 sub-job으로 나누고, 이를 물리적으로 분리된 구조에서 동시에 처리해서 완성하는 개념 (자동차 조립을 여러 사람이 동시에 하는 것, CPU의 Core 여러 개 표현)

따라서 parallelism 없이 concurrency를 가지는 것이 가능하다.

멀티 프로세서나 멀티 코어 구조가 발전하기 전에는 싱글 프로세서로 재빠르게 프로세스를 전환하여 concurrent하게 동작하지만 parallel하게 동작하는 것처럼 보이도록 하였다.

### 인터럽트(Interrupt)가 무엇인가요?

프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것. 즉 그러면 context switch 가 일어난다. 

지금 수행 중인 일보다 더 중요한 일(ex. 입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속해야한다.

외부/내부 인터럽트는 CPU의 하드웨어 신호에 의해 발생, 소프트웨어 인터럽트는 명령어의 수행에 의해 발생

- **외부 인터럽트**
    
    입출력 장치, 타이밍 장치, 전원 등 외부적인 요인으로 발생
    
    전원 이상, 기계 착오, 외부 신호, 입출력
    
- **내부 인터럽트**
    
    Trap이라고 부르며, 잘못된 명령이나 데이터를 사용할 때 발생
    
    > 0으로 나누기가 발생, 오버플로우, 명령어를 잘못 사용한 경우 (Exception)
    > 
- **소프트웨어 인터럽트**
    
    프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트)
    
    > 사용자가 프로그램을 실행시킬 때 발생
    > 
    > 
    > 소프트웨어 이용 중에 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다.
    > 

### 인터럽트 발생 시 처리 과정을 설명해 주세요.

인터룹트는 먼저 처리 되야되는 급한일이라고 생각하면 된다.  즉 그러면 컨텍스트 스위칭이 일어난다. 

1. 주 프로그램이 실행되다가 인터럽트가 발생했다.
2. 현재 수행 중인 프로그램을 멈추고, 상태 레지스터와 PC 등을 스택에 잠시 저장한 뒤에 인터럽트 서비스 루틴으로 간다. (잠시 저장하는 이유는, 인터럽트 서비스 루틴이 끝난 뒤 다시 원래 작업으로 돌아와야 하기 때문) 이는 커널에 저장이 된다.
3. 만약 **인터럽트 기능이 없었다면**, 컨트롤러는 특정한 어떤 일을 할 시기를 알기 위해 계속 체크를 해야 한다. (이를 폴링(Polling)이라고 한다. **폴링**을 하는 시간에는 원래 하던 일에 집중할 수가 없게 되어 많은 기능을 제대로 수행하지 못하는 단점이 있었다.)

### 데드락이 무엇인가요?

두 개 이상의 프로세스나 스레드가 서로 자원을 얻지 못해서 다음 처리를 하지 못하는 상태

무한히 다음 자원을 기다리게 되는 상태를 말한다.

### 데드락 발생조건 4가지를 설명해 주세요.

1. **상호 배제(Mutual exclusion)**
    
    > 자원은 한번에 한 프로세스만 사용할 수 있음
    > 
2. **점유 대기(Hold and wait)**
    
    > 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야 함
    > 
3. **비선점(No preemption)**
    
    > 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음
    > 
4. **순환 대기(Circular wait)**
    
    > 프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함
    > 

### 데드락의 해결방법에 대해서 설명해 주세요.

**예방**은 데드락 발생 필요 조건 중 어느 하나가 만족되지 않도록 하는 것이다. 가장 많이 사용하는 것은 순환 대기 조건을 만족시키지 않는 것이다. 

- 참고
    
    교착 상태 발생 조건 중 하나를 제거하면서 해결한다 (자원 낭비 엄청 심함)
    
    상호배제 부정 : 여러 프로세스가 공유 자원 사용
    
    점유대기 부정 : 프로세스 실행전 모든 자원을 할당
    
    비선점 부정 : 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납
    
    순환대기 부정 : 자원에 고유번호 할당 후 순서대로 자원 요구
    

**회피**는 실행환경에서 자원 요청에 대한 부가적인 정보를 이용해서 Deadlock의 가능성이 없는 경우에만 자원을 할당하는 것이다.  (*부가적인 정보 : 현재 사용 가능한 자원, 이미 할당된 자원, 앞으로 있을 자원 요청이나 반환 등*)

**탐지(Detection)**

자원 할당 그래프를 통해 교착 상태를 탐지함

자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함

**회복(Recovery)**

교착 상태 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법

> 프로세스 종료 방법
> 
> - 교착 상태의 프로세스를 모두 중지
> - 교착 상태가 제거될 때까지 하나씩 프로세스 중지
> 
> **자원 선점 방법**
> 
> - 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당 (해당 프로세스 일시정지 시킴)
> - 우선 순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점

### Race Condition은 무엇일까요?

공유 자원에 대해 여러 프로세스가 동시에 접근할 때, 결과값에 영향을 줄 수 있는 상태. 동시 접근 시 자료의 일관성을 해치는 결과가 나타남

### Race Condition(경쟁 상태)에 대하여 간단한 예시를 들어 설명해 주세요.

1. **커널 작업을 수행하는 중에 인터럽트 발생**
    - 문제점 : 커널모드에서 데이터를 로드하여 작업을 수행하다가 인터럽트가 발생하여 같은 데이터를 조작하는 경우
    - 해결법 : 커널모드에서 작업을 수행하는 동안, 인터럽트를 disable 시켜 CPU 제어권을 가져가지 못하도록 한다.
2. **프로세스가 'System Call'을 하여 커널 모드로 진입하여 작업을 수행하는 도중 문맥 교환이 발생할 때**
    - 문제점 : 프로세스1이 커널모드에서 데이터를 조작하는 도중, 시간이 초과되어 CPU 제어권이 프로세스2로 넘어가 같은 데이터를 조작하는 경우 ( 프로세스2가 작업에 반영되지 않음 )
    - 해결법 : 프로세스가 커널모드에서 작업을 하는 경우 시간이 초과되어도 CPU 제어권이 다른 프로세스에게 넘어가지 않도록 함
3. **멀티 프로세서 환경에서 공유 메모리 내의 커널 데이터에 접근할 때**
    - 문제점 : 멀티 프로세서 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우
    - 해결법 : 커널 내부에 있는 각 공유 데이터에 접근할 때마다, 그 데이터에 대한 lock/unlock을 하는 방법

### 프로세스가 도중에 중지되는 경우, 그 원인과 다시 실행할 수 있는 방법은 무엇일까요?

- 인터럽트 혹은 시스템 콜 등에 의해 프로세스가 중지될 수 있다.
- 아니면 선점 방식의 스케줄링의 경우, 타임 퀀텀이 지나게 되면 중지가 될것이다.
- 다시 실행할 수 있는 방법
    - PCB 안에 해당 프로세스의 정보가 저장되어 있기 때문에 추후에 실행 가능한 상태가 되면 PCB를 통해 다시 실행할 수 있다.

### 스레딩과 멀티스레딩에 대해 설명해 주세요

- **스레드** : 할당 받은 자원을 이용한 프로세스의 실행 흐름의 단위이다.
- **멀티 스레드** : 한 프로세스 내에서 이러한 스레드가 여러 개 동작하는 방식을 의미한다.
- 멀티스레드의 장점 : 프로세스를 여러개 두는 방식에 비해 컨텍스트 스위칭 비용이 적게 들며 응답 시간이 빠르다는 장점이 있다.
- 멀티스레드의 단점 : 같은 프로세스 내의 자원을 다른 스레드들과 공유하므로 동기화 문제를 고려해야 한다. 또한 프로세스가 종료되면 내부 스레드들 역시 모두 종료되므로 한 스레드가 프로세스를 의도치 않게 종료했을 경우 나머지 스레드들도 모두 종료될 수 있다는 단점이 있다.

### Thread Safe이 무엇인지 설명해 주세요.

- 멀티 쓰레드 또는 멀티 프로세스 상에서, 동기화가 이루어지는 것.
- 공유되는 자원이 동시성으로 인한 변함 없음을 보장. 멀티 스레드 환경에서 여러 스레드가 동시에 공유 자원에 접근할 때, 의도한대로 동작하는 것을 말합니다.
- Thread-safe하기 위해서는 공유 자원에 접근하는 임계 영역을 Mutex, Semaphore 등의 동기화 기법으로 제어해줘야 합니다.

### 운영체제의 Dual Mode 에 대해 설명해 주세요, 커널의 역할이 무엇인지 설명해 주세요.

- 이중 동작 모드(Dual Mode Operation)은 OS가 이상한 프로그램(Application faults)으로 인해 잘못 동작하거나 망가지지 않게 하는 아주 중요한 핵심 동작 원리입니다.
- '듀얼'이라는 말처럼 OS는 User mode와 Kernel mode 두 가지 모드를 두고 동작하는데요. 유저모드에서는 어플리케이션이 동작하고 사용자가 컴퓨터와 상호작용하는 등의 일이 이루어집니다. 반면, 커널모드에서는 드라이버, CPU, 메모리 등에 접근하고 명령을 내리며 이러한 작업들이 이루어지기 위한 근본적인 작업들을 처리하죠.
- 이 때, 특정한 권한 명령(Privileged Instruction)들은 무조건 커널 모드에서만 수행되어야 합니다. 유저 마음대로 OS의 작동을 좌지우지 할 수 있다면 하드웨어 장치나 메모리가 오동작하거나 심지어는 공격을 받을 수 있기 때문이죠. 특권 명령에는 인터럽트 핸들링, 사용자 모드에서 커널 모드로 전환, 입출력 관리 등이 있다.
- 그러면 언제/어떻게 유저모드에서 커널모드로 전환될까요? 바로 위에서 살펴본 인터럽트(Interrupt)가 발생할 때입니다. 그리고 인터럽트는 유저가 적절한 시스템 콜을 통해서 OS에게 커널 모드로 가서 요청한 작업을 해달라는 메시지를 보낼 때 발생하게 되죠.

### 시스템 콜에 대해 설명해 주세요.

시스템 호출(system call)은 운영 체제의 커널이 제공하는 서비스에 대해, 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스이다.

프로세스 제어, 파일 조작, 디바이스 조작, 정보 유지, 통신, 보호가 있다.

****Q. 시스템 콜은 왜 필요할까요****

우리가 일반적으로 사용하는 프로그램은 '응용프로그램'이다.

유저레벨의 함수만으로는 많은 기능을 구현하기 힘들다. 따라서 커널의 도움이 필요하다.

**커널(kernel)에 관련된 것은 커널 모드로 전환한 후에야, 해당 작업을 수행할 권한이 생긴다.**

### **Q. 서로 다른 시스템 콜을 어떻게 구분하는지 설명해 주세요**

- 커널은 내부적으로 각각의 시스템 콜을 구분하기 위해 **기능별로 고유번호를 할당**하고 그 번호에 해당하는 제어루틴을 커널 내부에 정의
- 커널은 요청받은 시스템 콜에 대응하는 **기능번호를 확인 -> 그에 맞는 서비스 루틴 호출**

### 임계영역이 만족해야 하는 조건이 있나요? 임계 영역을 프로세스들이 같이 쓸 수 있는 전제 조건을 설명해주세요.

공유 데이터의 일관성을 보장하기 위해 하나의 프로세스/스레드만 진입해서 실행(mutual exclusion) 가능한 영역

- **mutual exclusion** (상호 배제)
    - 한 번에 하나의 프로세스/스레드가 critical section에서 실행할 수 있다.
- **progress** (진행)
    - 아무도 critical section에 있지 않을 때, 들어가고자 하는 프로세스가 있으면 critical section에 들어가게 해주어야 한다.
- **bounded waiting** (한정된 대기)
    - 하나의 프로세스/스레드가 critical section에 들어가기 위해서 무한정 기다리는 상황이 되면 안된다.
    - 다른 프로세스들의 기아(Starvation)을 막기 위해서

### Context Switching의 문제점에 대한 해결방안을 설명해 주세요.

context switch 방안이 너무 많이 발생하게 되면, 교체하는 오버헤드가 실제 어플리 케이션을 실행하는 것을 방해한다.  

1. **오버헤드**: CPU가 실제 작업을 수행하는 것이 아니라, 프로세스나 스레드의 컨텍스트를 저장하고 불러오는 작업을 반복합니다. 이로 인해 CPU의 유휴 시간이 발생할 수 있습니다.
2. **캐시 무효화**: 현대의 CPU는 캐시 메모리를 통해 자주 사용되는 데이터나 명령어를 빠르게 접근합니다. Context Switching 발생 시 현재 실행 중인 프로세스의 데이터가 캐시에서 제거될 수 있어, 다시 해당 프로세스로 전환할 때 캐시 미스가 발생할 수 있습니다.
3. **자원 사용**: 컨텍스트를 저장하고 불러오기 위한 자원(메모리, 레지스터 등)이 필요합니다.

**해결 방안**:

1. **스레드 사용**: 멀티스레딩은 멀티프로세싱에 비해 상대적으로 적은 오버헤드로 컨텍스트 전환을 수행합니다. 이는 스레드들이 프로세스 내에서 메모리와 자원을 공유하기 때문입니다.
2. **Context Switching 최소화**: 스케줄러의 알고리즘을 조정하여 불필요한 컨텍스트 전환을 최소화합니다. 예를 들면, 긴 작업을 수행하는 프로세스가 여러 번의 짧은 컨텍스트 전환을 거치지 않도록 할 수 있습니다.
3. **Affinity Scheduling**: 특정 프로세스나 스레드를 특정 CPU 코어에 고정시켜 실행합니다. 이로 인해 해당 코어의 캐시에서 일관된 데이터를 유지하면서 컨텍스트 전환의 오버헤드를 줄일 수 있습니다.

### Mutex Lock 과 Semaphore 의 차이점이 무엇인가요?

- 차이
    1. 가장 큰 차이점은 관리하는 **동기화 대상의 개수**
        - Mutex는 동기화 대상이 오직 하나뿐일 때, Semaphore는 동기화 대상이 하나 이상일 때 사용한다.
    2. Semaphore는 Mutex가 될 수 있지만 Mutex는 Semaphore가 될 수 없다.
        - Mutex는 상태가 0, 1 두 개 뿐인 binary Semaphore
    3. Semaphore는 소유할 수 없는 반면, Mutex는 소유가 가능하며 소유주가 이에 대한 책임을 가진다.
        - Mutex 의 경우 상태가 두개 뿐인 lock 이므로 lock 을 가질 수 있다.
    4. Mutex의 경우 Mutex를 소유하고 있는 스레드가 이 Mutex를 해제할 수 있다. 하지만 Semaphore의 경우 이러한 Semaphore를 소유하지 않는 스레드가 Semaphore를 해제할 수 있다.
    5. Semaphore는 시스템 범위에 걸쳐있고 파일시스템상의 파일 형태로 존재하는 반면 Mutex는 프로세스 범위를 가지며 프로세스가 종료될 때 자동으로 Clean up 된다.

### 프로세스의 생명 주기

모든 프로세스는 state를 갖고 있고, 이는 운영체제 마다 다르다. 

- Ready : 메모리에 올라가 있는데, 돌고 있지 않지만 대기하는 상태. 스케줄링 알고리즘을 통해, 대기하고 있는 여러 Ready Process에서 Running 상태로 바꿔준다.
- Running : 실제로 실행되는 프로세스. 1개 밖에 없음
- Blocked : IO 또는 event wait 작업을 진행할 때 Block 상태로 간다. 해당 작업이 끝나면 다시 Ready 상태로 간다.
- 모든 프로세스는 CPU 와 IO 작업을 반복하는 과정을 거친다. IO를 한 후, Ready로 바꾼다.  잠시 대기하고 있는 프로세스 중 하나를 골라주면 CPU 사용도가 높아진다.
- Running State에서 반드시 Terminate를 할 때 Zombie 상태를 거친다. Parent가 Running 하면서 Child Process를 회수해주어 프로세스를 제거한다. 즉, 모든 프로세스는 일시적으로 좀비 상태에 머무르며, 누군가에 의해 Reaping 당하면 Terminate 상태로 간다.


# 스케쥴링

### CPU 스케줄링의 목적은 무엇인가요?

프로세스 스케줄러는 **멀티 프로그래밍**과 **time sharing**의 목적을 달성하기 위해 실행 가능한 여러 프로세스 중에서 하나의 프로세스를 선택해 실행한다. 

각 CPU 코어는 한번에 한 프로세스를 실행할 수 있다. 단일 CPU 코어 시스템에 반해 멀티 코어 시스템은 한 번에 여러 프로세스를 실행할 수 있다. 즉 이를 통해 컴퓨터 자원을 효율적으로 사용하게 한다. 

- 멀티 프로그래밍 (multiprogramming) : CPU 사용률을 최대화하기 위해 항상 프로세스를 실행하도록 한다. 어떤 프로세스가 CPU를 사용하다가 I/O 작업 등 CPU를 필요로 하지 않는 순간이 오면 다른 프로세스가 CPU를 사용할 수 있도록 한다.
    - CPU는 I/O burst 와 CPU burst를 연속적으로 반복하게 된다.
        - I/O burst: I/O 작업을 기다리는 시간
        - CPU burst: instruction 수행 시간
    - I/O burst 의 발생이 잦아지면서 CPU burst 가 짧아지게 되면서 CPU 효율성을 위해 스케줄링이 필요
    - CPU 와 I/O 장치 등 시스템 자원을 골고루 효율적으로 사용할 수 있음
    - 프로세스는 특성에 따라 다음 두 가지로 나눔
        - 1.I/O-bound process : CPU를 잡고 계산하는 시간보다 I/O에 많은 시간이 필요한 job (대부분 CPU burst가 매우 짧음)
        - 2.CPU-bound process : 계산 위주의 job(보통 CPU burst가 매우 긺)
- 시분할 (time sharing) : 각 프로그램이 실행되는 동안 사용자들이 상호작용할 수 있도록 프로세스 간 CPU 코어를 자주 전환하는 것이다. CPU가 하나의 프로그램을 수행하는 시간을 매우 짧은 시간(ms)으로 제한하여 프로그램을 번갈아 수행하도록 하면 CPU가 하나인 환경에서도 여러 사용자가 동시에 사용하는 듯한 효과를 가져올 수 있다.

### CPU 선점 방식과 비선점 방식의 차이점. 각 방식의 대표적인 알고리즘 이름

**선점 / 비선점 스케줄링**

- 선점 (preemptive) : OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우 (처리시간 예측 어려움)
- 비선점 (nonpreemptive) : 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리시간 예측 용이함)

### FCFS (First-Come, First-Served) Scheduling
- **비선점 스케줄링**
- 먼저 CPU를 요청하는 프로세스에 먼저 CPU가 할당된다.
- FIFO queue 를 사용해 쉽게 구현할 수 있다.
- 문제점) **convoy effect** : 먼저 들어온 어떤 프로세스의 CPU 처리 시간이 길 경우 다른 모든 프로세스들이 기다림으로서 더 짧은 프로세스가 먼저 진행될 수 있는 경우보다 CPU 및 장치 사용률이 낮아지는 현상

### SJF (Shortest-Job-First) Scheduling

- **비선점 스케줄링 방식** : CPU burst time이 가장 작은 프로세스에게 먼저 CPU를 할당한다. 만일 CPU burst time이 같다면, FCFS 방식을 적용한다.
- **선점 스케줄링 방식 (SRTF (Shortest-Remaining-Time-First) Scheduling)** : 새로 들어온 프로세스의 CPU burst time이 현재 실행 중인 프로세스의 남은 burst time 보다 작다면 현재 실행 중인 프로세스를 새로 들어온 프로세스가 선점한다.
- Priority Scheduling의 한 예이다. (우선순위 = CPU burst time)
- 주어진 프로세스 집합에 대해 **최소 평균 대기 시간**을 제공한다는 점에서 최적의 알고리즘이다. 하지만 CPU burst time을 알 수 있는 방법이 없기 때문에 CPU 스케줄링 수준에서 구현할 수 없다. 이에 대한 한 가지 접근 방식은 SJF 스케줄링을 근사화하는 것이며, 이전 CPU burst time 지수 평균으로 예측할 수 있다.
- 문제점) **starvation** : CPU 처리 시간이 긴 프로세스는 계속 Ready Queue의 뒤로 밀려나기 때문에 무한정 기다리는 상황이 발생할 수 있다.
- FCFS 보다 평균 대기 시간 감소, 짧은 작업에 유리
- HRN (Hightest Response-ratio Next)
    - 우선순위를 계산하여 점유 불평등을 보완한 방법(SJF의 단점 보완)
    - 우선순위 = (대기시간 + 실행시간) / (실행시간)

### RR (Round-Robin) Scheduling

- **선점 스케줄링**
- FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 `Time Quantum` 만큼 CPU를 할달 받음
    - `Time Quantum` or `Time Slice` : 실행의 최소 단위 시간
- 할당 시간(`Time Quantum`)이 크면 FCFS와 같게 되고, 작으면 문맥 교환 (Context Switching) 잦아져서 오버헤드 증가
- 각 프로세스는 **time quantum (or time slice)** 이라는 작은 시간 단위(10-100ms)를 갖게 된다. 프로세스는 1 time quantum 동안 스케줄러에 의해 CPU를 할당 받고, 시간이 끝나면 interrupt를 받아 Ready Queue의 tail에 배치된다.
- Ready Queue는 Circular FIFO queue 형태이다.
- RR의 평균 대기 시간은 긴 편이다. 하지만 공정하다. `n`개의 프로세스가 있고 time quantum이 `q`일 때, 어떤 프로세스도 `(n-1) x q` 시간 단위 이상 기다리지 않는다.

**Time quantum 설정 시 주의할 점**

- Time quantum이 너무 크다면 : FCFS와 같아진다.
- Time quantum이 너무 작다면 : Context Switching이 너무 빈번하게 일어나 overhead가 발생한다.

위와 같이 RR 알고리즘의 성능은 time quantum의 크기에 좌우될 수 있으므로 적절히 선정해야 하며 이는 context-switch time보다 큰 것이 좋지만 또 너무 커서는 안 된다. (경험적으로 CPU burst의 80프로는 time quantum보다 짧은게 좋다고 함)

### Priority Scheduling

- 정수로 표현된 우선순위가 더 높은 프로세스에게 CPU를 할당하는 스케줄링이다. 우선순위는 내부적/외부적으로 정의할 수 있다.
    - 내부적 : 시간 제한, 메모리 요구 사항, 열린 파일 수, 평균 I/O burst 대 평균 CPU burst 비율 등 측정 가능한 수량 사용해 계산
    - 외부적 : 프로세스의 중요성, 컴퓨터 사용에 대해 지불되는 자금의 유형 및 금액, 작업을 후원하는 부서, 기타 정치적 요인 등
- **선점 / 비선점 스케줄링** 모두 가능하다.
    - 선점 방식 : 새로 도착한 프로세스의 우선 순위가 현재 실행 중인 프로세스의 우선 순위보다 높으면 CPU 선점
    - 비선점 방식 : 같은 경우 단순히 새 프로세스를 Ready Queue의 맨 앞에 둔다.
- 문제점) **indefinite blocking**, **starvation**
    - 실행할 준비가 되었으나 CPU를 기다리는 프로세스는 block된 것으로 간주될 수 있다.
    - 우선 순위가 낮은 일부 프로세스는 무기한 대기 상태가 될 수 있다.
- 해결 방안) **Aging**, **Round-Robin과 결합**
    - Aging : 오랫동안 대기하는 프로세스의 우선순위를 점진적으로 높이는 방식으로 문제점을 해결할 수 있다. 예를 들어 대기 중인 프로세스의 우선순위를 매초 늘리는 것이다.
    - RR+PS : 우선순위가 가장 높은 프로세스를 실행하는데, 동일한 우선순위의 프로세스에 대해서는 Round-Robin 스케줄링을 적용한다.
- 정적/동적으로 우선순위를 부여하여 우선순위가 높은 순서대로 처리
- 우선 순위가 낮은 프로세스가 무한정 기다리는 Starvation 이 생길 수 있음
- Aging 방법으로 Starvation 문제 해결 가능

### Multilevel-Queue (다단계 큐)

- 작업들을 여러 종류의 그룹으로 나누어 여러 개의 큐를 이용하는 기법
- 우선순위가 낮은 큐들이 실행 못하는 걸 방지하고자 각 큐마다 다른 `Time Quantum`을 설정 해주는 방식 사용
- 우선순위가 높은 큐는 작은 `Time Quantum` 할당. 우선순위가 낮은 큐는 큰 `Time Quantum` 할당.
      

### Multilevel-Feedback-Queue (다단계 피드백 큐)

- 다단계 큐에서 자신의 `Time Quantum`을 다 채운 프로세스는 밑으로 내려가고 자신의 `Time Quantum`을 다 채우지 못한 프로세스는 원래 큐 그대로
    - Time Quantum을 다 채운 프로세스는 CPU burst 프로세스로 판단하기 때문
- 짧은 작업에 유리, 입출력 위주(Interrupt가 잦은) 작업에 우선권을 줌
- 처리 시간이 짧은 프로세스를 먼저 처리하기 때문에 Turnaround 평균 시간을 줄여줌


### **SJF를 preemptive(선점)한 방식으로 구현하기 위해서는 ready queue에 새로운 프로세스가 도착할 때마다 CPU에게 interrupt를 걸어야하나요?**

preemptive SJF는 새로운 프로세스가 도착하면, 도착한 프로세스의 CPU 시간(버스트 크기)과 현재 실행 중인 프로세스의 남은 CPU 시간을 비교하여 더 짧은 CPU 시간을 가진 프로세스를 수행 시킨다.

즉, **도착한 프로세스가 더 짧다면 CPU에 interrupt를 걸고, 아니라면 계속 진행**한다. ( 인터럽트 → 현재 작업 중단 → 커널을 깨워 인터럽트 처리 → 원래의 작업으로 복귀 )

- **Q-1. 어떻게 새로운 프로세스가 도착했음을 알고, 그것이 더 짧은 프로세스임을 알고, CPU 제어권을 넘기는가요?**
    
    CPU 시간(버스트 크기)의 정확한 값을  사전에 아는 것은 사실상 불가능에 가깝다. 그렇기 때문에 **예측(지수 평균)**을 통해 진행한다. 새로운 프로세스가 더 짧은 프로세스일 경우, **Dispatcher를 통해** CPU 스케줄러에 의해 선택된 프로세스에게 **CPU의 제어권을** 넘겨준다.
        

### **multilevel queue에서 우선순위 높은 queue의 프로세스가 끝나서 두번째 queue의 프로세스를 처리하던 중 첫번째 queue에 프로세스가 채워지면 preemptive하게 작동하는가?**

두번째 queue가 실행되려면 앞의 queue들이 다 비어있어야한다. 그렇기 때문에 두번째 queue를 처리하던 중 첫번째 queue가 채워지면 두번째는 잠시 뒤로 물러나고 우선순위가 높은 프로세스가 실행된다.(preemptive 방식)

### Round Robin 스케줄링 방식에서 time quantum 설정에 따른 결과를 설명해보세요. 오버헤드가 어떤건가요

time Quantom이 커지면, 결과적으로 FCFS, 그리고 작다면 context switch 비용이 있기 때문에 사이에 적절하게 조절하는게 필요하다. 

### **multilevel queue time slice방식에서 각 queue에 CPU time을 비율로 할당한다는 것의 의미는 무엇인가요? 어떤 것에 대한 비율인가요?** 별개의 Queue를 두는 방식이 왜 load sharing과 관련이 있는가?

**각각의 큐에 다른 time quantum을 설정해주는 것**을 의미한다.

예시로는 foreground queue의 RR에 20%를, background queue의 FCFS에 80%를 할당하는 것이 있다.

time quantum이 길어질수록 FCFS방식의 성격을 띄기 때문에 결국 우선순위가 낮은 background 프로세스에 상대적으로 더 긴 time quantum을 할당하여 FCFS 느낌이 된다.

### FCFS 스케줄링을 개선한 스케줄링 방식에 대하여 설명해보세요.

라운드 로빈 → time Quantom + FCFS 이다. 

---
# 페이징

### RAM을 주기억장치라고 표현하는 이유는?

RAM과 CPU에서의 동작으로 이루어집니다.  

**1. 보조기억장치에서 주기억장치로 프로그램을 불러온다. (부팅 또는 로딩)**

**2. 주기억장치에서 프로그램을 기억하고 CPU와 통신할 준비를 한다. (동작 및 구동)**

**3. 주기억장치와 CPU에서 데이터를 주고받으며 프로그램을 구동한다. (동작 및 구동)**

### 지역성이 뭔가요? 그리고 종류는?

- **지역성** : 데이터 접근이 시간적, 혹은 공간적으로 가깝게 일어나는 것
    - **시간적 지역성(Temporal locality)** : 특정 데이터가 한 번 접근되었을 경우,가까운 미래에 또 한 번 데이터에 접근할 가능성이 높음
    - **공간적 지역성(Spatial locality)** : 액세스 된 기억장소와 인접한 기억장소가 액세스 될 가능성이 높음
- 쓰레싱 (Thrashing) 빈번한 페이지의 부재
- 시스템 성능을 떨어뜨림
- 주로 잘못된 교체 정책과 프로세스에 할당된 프레임 수가 너무 작아서 발생
- 지역성을 잘 고려하면 스레싱 발생 확률 낮출 수 있다.
1. 멀티프로그래밍 정도가 낮을 때 CPU는 CPU utilization을 높이기 위해 프로세스를 적재한다.
2. 어느 정도는 견딜 만 하지만, 물리 메모리는 한계치가 존재한다. 즉, **프로세스당 할당되는 프레임은 제한**된다.
3. 적은 프레임을 가진 프로세스는 **보다 빈번하게 page fault를 일으킨다.** 이 현상은 **프로세스가 메모리에 적재될 때마다 증가**한다.
4. CPU는 CPU utilization이 낮은 것을 보고 다음과 같이 생각한다. "메모리에 적재된 프로세스가 부족하다." 하지만 실제로는 **page fault를 처리하느라 CPU를 사용하지 않는 것**이다.
5. 어느 임계점을 지나면, **모든 프로세스는 page fault만 하느라 CPU utilization이 급격하게 감소**된다. 이것을 **Thrashing**이라 한다.

### 만약 필요한 데이터가 하드디스크에 있다면, CPU에서 바로 하드디스크에 접근해서 데이터를 가져오면 더 빠를텐데 왜 굳이 모든 계층구조를 모두 통해서 가져올까요?

프로그램의 실행은 **지역적 특성**을 띄고 있기 때문에 계층적으로 메모리를 두었을 때 더 성능이 좋아지기 때문이다.즉, 모든 메모리의 역할이 피라미드 구조에서 자신보다 아래에 있는 메모리를 캐쉬하기 위해서 존재하는 것으로 이해해야 한다.

우리가 사용하는 시스템에서는 캐쉬 메모리가 높은 성능 향상을 가져다 준다.그만큼 연산에 필요한 데이터가 캐쉬 메모리에 존재할 확률이 아주 높다는 뜻이다.메인 메모리를 제외하고 L1캐쉬, L2 캐쉬에 연상에 필요한 데이터가 존재할 확률이 90%정도 된다.하드디스크에서 데이터를 읽어들이는 빈도수는 전체 메모리 접근 빈도수의 불과 몇퍼센트밖에 되지 않는다.

결국 크게 보면 하드디스크에서 바로 접근하지 않는 것은 메모리의 지역성을 생각하여 나타난 현상이라고 볼 수 있다.

### 메모리 구조의 순서가 어떻게 되는지 CPU에서 가까운 순으로 말해보세요.

레지스터, 캐시, 주기억장치, 보조기억장치 순서입니다.
- **레지스터** : CPU 내에 존재하는 메모리로 빠르고 작다.
- **캐시** : CPU와 주기억장치 사이에서 중간 저장소 역할을 함. Locality 특성 이용
- **주기억장치** : 현재 수행되는 프로그램과 데이터 저장
- **보조기억장치** : 용량이 크나 느리다.

### 메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)

## first-fit

- 가장 처음으로 요구하는 메모리에 맞는 공간에 할당하는 방식

## best-fit

- 남은 공간 중에 가장 internel fragmentation이 적은 메모리 공간에 할당하는 방식
- 가장 적합한 공간이 어디인지 찾아야되는 시간 필요

## worst-fit

- 가용 공간 중에 가장 큰 공간에 할당하는 방식

### 가상메모리에 대해 설명해 주세요.

시스템이 실행될 때 여러 프로세스가 실행이 되는데, 각 프로세스가 실행되기 위해서는 메모리를 필요로 한다. 그러나 메모리는 한정되어 있다. 실행되어야 하는 모든 프로세스가 필요한 시기에 적절하게 메모리의 할당을 받을 수 있도록 메모리 관리가 필요하다.

- **프로세스 전체가 메모리 내에 올라오지 않더라도 실행가능하도록 하는 기법**
- 필요한 부분만 메모리에 올림으로써 메모리에 올라가는 프로세스의 크기를 줄이는 요구 페이징 기법을 사용
- 프로세스 이미지를 모두 메모리에 올릴 필요가 없어지며, 메모리 용량 부족 이슈를 해결할 수 있다.

### 세그멘테이션과 페이징의 차이점에 대해 설명해 주세요.

페이징과 세그멘테이션 모두 프로그램을 실행하기 위해 디스크에 있는 내용을 분할하여 메모리에 적재하는 불연속 메모리 관리 기법이지만, 페이징의 경우 프로그램을 같은 크기의 페이지로 분할하는 데에 비해, 세그멘테이션은 논리적 의미를 기준으로 세그먼트를 분할한다.

### Paging을 이용한 주소 변환 과정에 대해 설명해 주세요. (Page table, PTE, PFN 개념 언급)

1. 프로세스의 가상 주소로 VPN과 offset을 알아낸 뒤, 해당 프로세스의 VPN 값으로 프로세스의 page table에서 PTE 정보를 가지고 온다.
2. PTE(page table entry)정보에서 PFN(page frame number)을 추출한다.
3. PFN, offset을 사용해서 실제 메모리 주소를 얻는다.
- PTE: **page table에서 각 page의 정보**
- Page table: **가상 주소를 실제 메모리 주소로 매핑(변환)힐 때 사용되는 자료 구조**
- PFN: Physical Frame Number (= PPN, Physical Page Number)

### 세그먼테이션으로 주소변환 하는 방법에 대해 설명해 주세요.

가상 주소는 **segment id + offset**으로 구할 수 있다.

segment id로 base 값을 찾고, offset을 계산하여 segmentation fault 발생 유무를 확인한다.

**base값에 offset을 더하여** Physical memory 주소를 찾는다.

### MMU에 대해 설명해 주세요.

가상메모리 시스템에서 CPU는 가상 주소를 통해 물리 주소에 접근하여 작업한다.

이 때, **가상 주소를 물리 주소로 변환**하는 하드웨어 디바이스를 MMU라고 한다.

- 가상 메모리 주소(논리 메모리 주소)를 실제 메모리 주소로 변환하는 역할을 한다.
    - OS를 통해 페이지 테이블에 접근하고, 변환 작업을 진행한다.
- 일반적으로 CPU 내에 존재하지만, 별도의 통합 칩 (IC)에서 작동하기도 한다.
- Memory Protection 기능을 제공한다.
    - 보호되는 메모리 영역에 접근하지 못하게 한다.
- 메모리의 실제 배열과 상관 없이 연속된 메모리로 취급할 수 있게 한다.

### TLB에 저장 가능한 공간이 꽉 찼을 경우 새로운 프로세스가 실행된다면, 어떤 프로세스를 빼고 새로운 것을 넣어야 하는지 과정에 대해 설명해 주세요. (TLB Replacement policy)

목표는 **TLB miss rate를 최소화** 하는 것(TLB hit rate를 향상시키는 것과 같은 말이다)

- LRU(Least-recently-used) : 최근에 사용하지 않는(예전에 사용하고 지금은 사용하지 않는) Process를 내보내는 방법이다.
    - LRU는 Temporal Locality의 장점을 이용한다.
- Random policy : 이름 그대로 랜덤하게 제거하는 방법이다.

### TLB를 사용할 때 Context Switching이 발생한다면 어떻게 해결하는지 설명해 주세요. (2가지 해결방안)

첫 번째 방법은 Context switch가 발생할 때 **기존 프로세스의 주소변환 정보를 TLB에서 모두 지워버리는 것**이다.

이를 **flush**라고 하는데, TLB의 주소 변환 정보중 valid 비트의 값을 0으로 초기화하여 TLB의 내용을 지우게 된다.

두 번째는 TLB에서 **ASID(address space identifier)라는 정보를 추가**한다.

**어떤 프로세스의 정보인지 구별**하기 위해 TLB에서 ASID를 제공한다.

이를 통해 프로세스마다 다른 ASID 정보를 저장하여 주소 변환을 성공적으로 수행할 수 있도록 한다.

### TLB가 메모리 성능을 어떻게 향상시키는지 TLB hit rate 와 Spatial Locality 개념과 연관지어 설명해 주세요.

TLB에서 주소 변환이 성공하는 것을 TLB Hit이라고 합니다. 그리고 TLB Hit가 된 확률을 TLB hit rate라고 합니다.

모든 cache와 마찬가지로 TLB도 하나의 cache로써 spatial, temporal locality(공간, 시간 지역성)을 가집니다. 한 번 접근한 뒤에 다시 접근할 때는 이미 TLB에 모든 변환 정보가 존재하기 때문에 100%의 TLB hit rate로 주소 변환이 수행됩니다.

이러한 Spatial Locality 특성 때문에 TLB hit rate를 높이게 되어 메모리 성능을 향상시킵니다.

### 외부 단편화, 내부 단편화에 대하여 설명해보세요. 외부 단편화를 해결하기 위한 전략이 있다면?

### Fragmentation

- **External Fragmentation** : Total memory space는 요청에 맞지만, 연속적이지 않다.

 → compaction 으로 해결 가능하다. free memory를 하나의 큰 block 으로 만든다. 이는 dynamic relocation일때만 가능하고, 실행 시간 일 때만 가능하다. **가장 큰 문제는 i/o 버퍼를 특정 위치에 latch 시켜야 함. 버퍼를 움직이면, 디바이스가 알지 못한다.** 

- **Internal Fragmentation** : 할당된 메모리가 요청한 것에 비해 조금 크다.

프로세스의 물리 주소 공간이 연속되지 않아도 되는 메모리 관리 기법⇒  외부 단편화를 피할 수 있다.

- 대표적인 두가지 기법이 있다.
    - 페이징과 세그멘테이션

### Reentrant의 개념에 대하여 설명하고, Thread-safe 와의 차이점을 설명해주세요.

- Reentrant는 **재진입성**이라는 의미로, 어떤 함수가 Reentrant하다는 것은 여러 스레드가 동시에 접근해도 언제나 같은 실행 결과를 보장한다는 의미이다.
- 이를 만족하기 위해서 해당 서브루틴에서는 공유자원을 사용하지 않으면 된다.
    - 예를 들어 정적(전역) 변수를 사용하거나 반환하면 안 되고 호출 시 제공된 매개변수만으로 동작해야한다.
- 따라서, Reentrant하다면 Thread-safe하지만 그 역은 성립하지 않는다

### TLB가 나오게 된 배경은 무엇이고, TLB 개념에 대해 설명해 주세요.

**TLB 필요성**

- 페이지 테이블을 레지스터에 저장하는 경우 빠르게 접근할 수 있지만 큰 page table을 사용할 수 없다.
- 그러므로 페이지 테이블을 메인 메모리에 저장하고 **페이지 테이블 기준 레지스터(page-table base register, PTBR)가** 페이지 테이블의 주소 값을 가지고 있다.
    - 페이지 테이블 길이 레지스터 (Page-table length register, PTLR)
- 메인 메모리에 페이지 테이블을 저장하려면 Context-Switching 속도가 빨라지지만 **메모리 access 시간이 느려**질 수 있다.
- 페이지 번호 기준으로 PTBR 오프셋의 값을 사용해서 페이지 테이블의 항목을 찾는다. **(첫 번째 메모리 access)**
- 이렇게 얻은 프레임 번호와 페이지 오프셋을 결합하여 실제 주소에 접근한다. **(두 번째 메모리 access)**
- 메모리 접근 시간이 느려진다. → 이러한 **문제를 해결하기 위해 TLB를 사용**한다.

**정의**

자주 참조되는 **Page Table Entry를 저장하는 하드웨어 캐시**이다.

- **MMU 내부(CPU)에 위치**한다.
    - 메모리에 접근하는 대신 TLB에 접근하여 시간을 절약할 수 있다.
- TLB는 크기가 작기 때문에, **검색 시간이 짧다**.
    - 보통 빠르고 비싼 SRAM으로 구성된다.
        - 메인 메모리는 느리고 저렴한 DRAM으로 구성된다.

### TLB를 사용한 전체적인 페이지 탐색과정에 대해 설명해 주세요.

1. MMU가 **TLB에 접근**하여 Virtual Address를 이용해 **테이블 엔트리를 찾는다**.
    - Page Number와 ASID를 이용한다.
    - MMU는 CPU 내부의 레지스터 값을 통해 실행 중인 PID를 알 수 있다.
        - 이를 TLB의 ASID와 비교한다.
2. TLB에 해당 페이지 엔트리를 찾으면(**TLB Hit**), 해당 **프레임 번호를 반환**한다.
    - **TLB Miss**의 경우
        - Page Table에 접근하여 필요한 Page Table Entry를 찾는다.
            - Page Fault 발생 시 Paging 기법과 동일한 방법으로 Page를 로드한다.
        - 찾은 Page Table Entry를 TLB에 적재한다.
        - 이후 **TLB Hit** 된다.
3. Frame Number와 Offset을 결합하여 **물리 메모리 접근에 성공**한다.

### TLB hit과 miss가 어떤 의미인지 설명해 주세요.

**TLB Hit**

- **TLB에서 필요한 페이지 정보를 찾은** 상황을 의미한다.

**TLB Miss**

- **TLB에 필요한 페이지 정보가 존재하지 않아** 찾지 못한 상황을 의미한다.

**TLB Flushing**

- TLB를 강제로 초기화 하는 것을 의미한다.
    - Full flushing - 전부 초기화
    - Partial Flushing - 부분 초기화
- Context Switching이 발생하면 이전 프로세스의 Entry는 필요하지 않으므로 초기화한다.
- 페이지 테이블이 변경되면 페이지의 위치가 변할 수 있으므로 초기화한다.

### 세그먼테이션은 무엇이고, 세그먼테이션으로 인해 어떤 장점이 있는지 설명해 주세요.

서로 다른 크기를 가진 논리적 블록이 비연속적 공간에 배치되는 것

- 프로세스를 물리적 단위인 페이지가 아닌 논리적 단위인 세그먼트로 분할해서 메모리에 적재하는 방식이다.
- 세그먼트는 논리적 내용을 기준으로 프로그램을 분할하기 때문에 크기가 같지 않다.
- 장점
    - 내부 단편화 문제가 해소된다.
    - 보호와 공유 기능을 수행할 수 있다. 프로그램의 중요한 부분과 중요하지 않은 부분을 분리하여 저장할 수 있고, 같은 코드 영역은 한 번에 저장할 수 있다.
- 단점
    - 외부 단편화 문제가 생길 수 있다.

### 페이지 폴트(page fault)에 대해 설명해 주세요.

프로세스가 메모리에 올라와 있지 않은 페이지에 접근 시 발생. 

- 페이지 테이블 항목이 무효로 설정되어 있으면 **페이지 폴트 트랩(page-fault trap)** 발생
- 페이지 폴트가 발생하는 두 가지 경우 (Valid-Invalid Bit 가 i 인 경우)
    - 가상 주소 공간상에 정의되지 않은 경우, Invalid reference (접근 불가능한 공간)
    - 유효하지만 disk에 존재하는 경우, Just not in memory (memory에 존재 X)

> 참조 지역성(locality of reference)
> 
> - 프로그램의 어느 한 특정 작은 부분만 한동안 집중적으로 참조한다.
> - 한 명령어에도 여러 개의 페이지 폴트 발생 확률은 매우 작다.
> - 그러므로 요구 페이징은 만족할 만한 성능을 보인다.

### **페이지 폴트 처리 과정**

- 프로세스에 대한 내부 테이블(internal table)을 검사해서 그 메모리 참조(reference)가 유효 또는 무효인지 알아낸다.
- 만약 무효한 페이지에 대한 참조라면 그 프로세스는 중단된다. 만약 유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 그것을 disk로부터 가져온다.
- 빈 공간, 즉 가용 프레임(free frame)을 찾는다. (메인메모리)
- disk에 새로 할당된 프레임에 해당 페이지를 읽어 온다.
- disk가 읽기가 끝나면, 이 페이지가 유지하고 있는 내부 테이블을 수정
- 트랩에 의해 중단되었던 명령어를 다시 수행

### Multi-level Page Tables에 대해 설명해 주세요. (page directory 언급)

레벨을 늘릴 수록 **페이지 테이블 크기가 작아지고, Memory Acess 수가 많아진다.** → tradeoff이다.

- Page Directory Entry : Page table을 관리하는 entry이다.
- 어느 테이블이 valid한지 관리한다.
- 장점
    - 쓰이는 페이지만 담아놓을 수 있다.
- 단점
    - 시간과 공간에 대한 trade-off 이다.
    - 복잡도

### Paging(페이징)이 왜 나오게 되었고, 개념에 대해 설명해 주세요.

- 단편화 문제를 압축방식으로 해결하려 했지만, 이 또한 비용이 발생한다. 좀 더 근본적인 해결책을 찾다가 발견한 것이 **'페이징'**이다.
- 단편화가 문제가 되는 이유는 프로그램을 연속된 메모리공간에 탑재해야만 하기 때문이다. 이러한 '연속적'이라는 조건을 없어지도록 하는 것이 페이징 기법이다.
- 즉, 이다.
    
    페이징 기법은 연속된 물리공간을 필요로 하지 않으면서도, 실행시간 및 주소결속 등 프로그램 수행에는 문제가 없도록 하는 방식
    
- 프레임, 페이지, 페이지테이블 3개로 이루어진다.
- 전체 물리적 공간을 같은 '**프레임**' 단위로 나누어놓고, 로 나눈다. 그리고 시킨다. 즉 페이지 테이블은 일종의 주소 변환 테이블의 역할을 하여 각 페이지에 해당하는 프레임 번호를 보유한다.
    
    논리적 공간도 프레임과 같은 크기의 '**페이지**' 단위
    
    '**페이지 테이블**'을 통해 페이지를 프레임에 매핑
    

### Paging의 장점과 단점에 대해 설명해 주세요.

- **단점** : 페이지 테이블 사용으로 분할방식 대비 주소결속에서 오버헤드 발생 (속도 저하) / 페이지 테이블의 메인메모리 저장으로 공간 낭비
- cf. TLB 사용 및 페이지 테이블의 다단계 구성(구조 개선)으로 단점 완화 가능
- **장점** : 외부 단편화 문제 해결 / 페이지 공유 가능 (메모리 공간의 효과적 활용) / 페이지 보호 가능

### 페이징 교체에 대해 설명해 주세요.

- 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 page fault(페이지 부재)가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 된다.
- 하지만, 물리 메모리가 모두 사용중인 상황이라면 **페이지 교체**가 이뤄져야 한다.
- 페이지 교체 흐름
    1. 디스크에서 필요한 페이지의 위치를 찾는다.
    2. 빈 페이지 프레임을 찾는다.
        1. 페이지 교체 알고리즘을 통해 희생될 페이지를 고른다.
        2. 희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다.
    3. 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다.
    4. 사용자 프로세스 재시작

### 외부 단편화가 발생할 때마다 압축을 시행해주면 되는 것인가?그렇다면 압축 외에 외부 단편화를 해결하는 방안은?

- 통합
    - 하나의 작업이 끝났을 때 서로 빈 공간이 있는 메모리를 하나로 합치는 방법
    - 비어있는 홀이 연속적인 경우 둘을 합쳐 더 큰 hole로 만들어준다.
- 압축
    - 현재 사용 중인 메모리를 적절히 움직여 다 붙이고 큰 hole을 만드는 방법
    - 메모리에 적재된 프로세스의 메모리를 동적으로 이동시킨다.
    - execution time binding일 때 사용 가능하다.
    - 압축하는 동안 시스템이 모든 일을 그만둔다. → 실시간 시스템에서 사용하면 큰일남
    - 압축하는 과정에서 시스템 자원 cost가 크다.
    - 성능을 포기하고 메모리 효율을 높이는 방법

### 페이지 크기에 대한 Trade-Off를 설명해 주세요.

### 페이지 크기가 작을 때

일반적으로 페이지 크기가 작을수록 프로세스가 사용하는 메모리의 양이 더욱 정확해지므로, 프로세스의 성능이 향상될 수 있다. 또한 프레임 내부 단편화도 감소한다. 하지만 페이지 크기가 작을수록 페이지 테이블의 크기가 커지므로 더 많은 메모리가 필요하다.

### 페이지 크기가 클 때

반면, 페이지 크기가 크면 페이지 테이블의 크기가 작아지므로 메모리 사용량이 감소한다. 그러나 페이지 크기가 클수록 프로세스가 사용하는 메모리의 양이 더욱 불확실해지므로 페이지 오버헤드가 발생할 수 있다. 또한 내부 단편화가 증가한다.

### 페이지를 교체하는 다양한 방법들에 대해 알려주세요.

### FIFO 페이지 교체 First-In-First-Out Page Replacement

물리메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다.

- 장점
    - 이해하기 쉽고, 프로그래밍도 쉽다.
- 단점
    - 오래된 페이지가 불필요한 정보를 포함한다고 보장할 수 없다.
    - 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높일 수 있다.
    - Belady의 모순 : 페이지를 저장할 수 있는 페이지 프레임의 개수를 늘려도 되려 페이지 부재가 더 많이 발생한다는 모순이 존재한다.

### 최적 페이지 교체 Optimal Page Replacement

- 최적의 교체 알고리즘인 OPR(Optimal Page Replacement)가 현실적으로 가능할까요?

모든 알고리즘보다 낮은 페이지 부재율을 보이며 Belady의 모순 또한 발생하지 않는다. 이 알고리즘의 핵심은 **앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체**하는 것이다.

- 장점
    - 가장 낮은 페이지 부재율을 보장한다.
- 단점
    - 구현이 어렵다. 모든 프로세스의 메모리 참조 계획을 미리 파악할 수 없기 떄문이다.

### LRU 페이지 교체

최적 알고리즘의 근사 알고리즘. 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체한다.

### LFU 페이지 교체

참조 횟수가 가장 적은 페이지를 교체한다. 활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어졌다.

- 특징
    - 어떤 프로세스가 특정 페이지를 집중적으로 사용하다가 다른 기능을 사용하게 되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋 날 수 있다.
    - OPT 알고리즘을 제대로 근사하지 못해 잘 쓰이지 않는다.

### MFU 페이지 교체

참조 횟수가 가장 적은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정에 기반한다.

### 동적 재배치 기술에 대해 설명해 주세요.

메모리 액세스 할 때마다 translation을 Hardware의 도움을 받는 것이다. MMU는 translation을 위한 Base Register 와, Protection을 위한 BOUNDS Register를 따로 둔다. (CPU 에 존재하는 하드웨어이다.) 

- Base Register : loading 하고자 하는 Process의 Location (smallest physical Address)
- Bounds Register : 프로세스의 virtual Address의 사이즈. 이는 에러를 체크해주기 위함이다.
- 장점
    - Protection 가능
    - MMU 와 few Register → inexpensive implementataion
    - Fast
- 단점
    - Process가 Physical Memory에   프로세스 별로 Continuous하게 올라가야 한다.
    
    → external fragmentaion 해결하기 어려움
    
    - address space를 share 하는 것 구현하지 못한다.

### 전처리 - 컴파일 - 어셈블리 - 링킹
전처리기는 전처리 지시자가 포함된 헤더를 포함하는 구문은 해당 헤더 파일 내부 코드로 변경해주고, 매크로 상수나 함수는 정의한 내용으로 소스코드를 변경해준다.

**컴파일**은 **인간이 이해할 수 있는 언어로 작성된 소스 코드**(고수준 언어 : C, C++, Java 등)를 **CPU가 이해할 수 있는 언어**(저수준 언어 : 기계어)로 **번역(변환)하는 작업**을 말한다.소스 코드는 컴파일을 통해 기계어로 이루어진 실행 파일이 된다. 이 파일을 실행하면 실행 파일 내용이 운영체제의 Loader를 통해 메모리에 적재되어 프로그램이 동작한다.

**어셈블(Assemble)** 단계는 컴파일 단계에서 만들어진 저수준 언어 코드를 2진수로 이루어진 완전한 기계어로 번역해 `.o` 확장자를 가지는 목적 파일로 만들어주는 단계로, 어셈블러(Assembler)라는 프로그램이 이를 담당한다.

**링킹(Linking)**은 컴파일러가 생성한 목적 파일들과 정적 라이브러리를 합쳐 하나의 실행 파일을 만드는 작업이다. 정적 라이브러리는 이미 그 자체로 컴파일되어 손쉽게 가져다 사용할 수 있는 함수들의 집합이기 때문에 앞서 새롭게 컴파일한 목적 파일들과 손쉽게 합쳐질 수 있다.
